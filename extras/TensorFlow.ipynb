{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a1f8ad-5c82-4bab-b62a-f2bfc791497d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebe6177-33ba-481a-97d4-56537ef5deca",
   "metadata": {},
   "source": [
    "Ustalamy tu stałą DEVICE, która globalnie definiuje jakiego urządzenia ma użyć tensorflow. W komórkach poniżej jest kod, który upewnia się że odpowiednie urządzenie jest używane. Nie musimy dalej się martwić o przerzucanie pojedynczych wektorów pomiędzy urządzeniami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318b4b00-d7a8-40af-9feb-fbf2db7ee188",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"CPU\"\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "logging.basicConfig(format='%(levelname)s: %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf036958-ed5c-417a-9b54-bf8c38abc021",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEVICE == 'GPU':\n",
    "    gpu = tf.config.list_physical_devices('GPU')\n",
    "    assert gpu\n",
    "    tf.config.experimental.set_memory_growth(gpu[0], True)  # dodatkowa opcja, gdy jest mało pamięci na karcie. Dzięki niej, tenosrflow bardzo ostrożnie nią zarządza\n",
    "\n",
    "elif DEVICE == 'TPU':\n",
    "    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
    "    tf.config.experimental_connect_to_cluster(resolver)\n",
    "    tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "    assert tf.config.list_logical_devices('TPU')\n",
    "\n",
    "else:\n",
    "    tf.config.set_visible_devices([], 'GPU')\n",
    "    tf.config.set_visible_devices([], 'TPU')\n",
    "    visible_devices = tf.config.get_visible_devices()\n",
    "    for device in visible_devices:\n",
    "        assert device.device_type not in ['GPU', 'TPU']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7badf5-8784-4199-b2d3-b7be435f7418",
   "metadata": {},
   "source": [
    "**Funkcje pomocniczne**\n",
    "* get_logdir -- tworzy podfolder do każdego trenowania modelu. Poprawia organizacje pracy z TensorBoard\n",
    "* plot_training -- szybkie, proste rysowanie metryk uczenia. Przydatne gdy nie ma potrzeby używania całego TensorBoard\n",
    "* mount_drive -- podpina dysk google przy pracy na Collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863db7f3-b120-476f-a019-e3df22c046b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir=./logs --port=6006\n",
    "def get_logdir(root_logdir=None):\n",
    "    if not root_logdir:\n",
    "        root_logdir = os.path.join(os.curdir, \"logs\")\n",
    "    run_id = datetime.datetime.now().strftime(\"run_%Y-%m-%d_%H:%M:%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "\n",
    "def plot_training(history, limit_grid=None, filepath=\"\"):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "    plt.grid(True)\n",
    "    if limit_grid:\n",
    "        plt.gca().set_ylim(*limit_grid)\n",
    "    if filepath:\n",
    "        plt.savefig(filepath)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def mount_drive():\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    return '/content/drive/My Drive/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea05ba8a-015a-4bec-b394-57b7e54c2294",
   "metadata": {},
   "source": [
    "# Quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2e948c-eeb2-434a-a156-12678076a81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Szybka normalizacja danych\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e8f57c-0e39-4d8d-ae75-1fac47fadf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f1473d-c2a9-489d-8fc7-923ddaa4634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "history = model.fit(X_train, y_train, epochs=3, batch_size=32, validation_split=0.2, \n",
    "                    callbacks=[keras.callbacks.TensorBoard(get_logdir(\"my_logs\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05fd5de-ef5d-46ce-b859-74fc9fa7d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef72280-993e-40d1-b02e-165e4da00860",
   "metadata": {},
   "source": [
    "# In-depth modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b108af32-0528-40de-8240-265adcec1f06",
   "metadata": {},
   "source": [
    "TensorFlow zaiwera wiele warstw do preprocessingu, jest to wygodne bo możemy połączyć preprocessing z siecią i finalnie karmić model surowymi danymi.\n",
    "Różne ciekawe warstwy:\n",
    "* Normalization\n",
    "* Discretization\n",
    "* TextVectorization\n",
    "* CategoryEncoding\n",
    "* ... \n",
    "\n",
    "W tej kategorii są również warstwy za pomocą których możemy robić augmentacje obrazu (te warstwy będą aktywne tylko w czasie treningu, potem możemy je nawet odrzucić)\n",
    "* RandomCrop\n",
    "* RandomFlip\n",
    "* ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27811f94-13cf-4b4c-acfd-e6726528b619",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "preprocessing_layer = tf.keras.layers.Normalization(axis=None)\n",
    "preprocessing_layer.adapt(X_train)  # adaptujemy / fitujemy warstwę normalizującą na całym zbiorze treningowym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76c9f8a-e583-4559-bbd3-15f6bd00fbd3",
   "metadata": {},
   "source": [
    "*Wszystkie poniższe metody tworzenia modelu są równoważne, uczymy je w ten sam sposób*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c123d00-461c-41cc-8fe7-0917cf6f2d52",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Sequential API -- szybkie, proste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b212e73-7ba1-46db-b2a7-2e8dcef92399",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    preprocessing_layer,  # dorzucamy gotowy preprocessing do modelu\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2e659d-e4e9-4280-8c13-d4d9fef8bce1",
   "metadata": {},
   "source": [
    "## Functional API -- pośrednie. Przydatne gdy model nie jest sekwencyjny -- np. rozdwojone wyjście, skipowe połączenia itp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b58e8d-fc5e-4705-aba9-6cf59e709a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = keras.layers.Input(shape=(28, 28))\n",
    "flatten = keras.layers.Flatten()(input_layer)\n",
    "preprocess = preprocessing_layer(flatten)\n",
    "dense1 = keras.layers.Dense(300, activation=\"relu\")(preprocess)\n",
    "dense2 = keras.layers.Dense(100, activation=\"relu\")(dense1)\n",
    "output_layer = keras.layers.Dense(10, activation=\"softmax\")(dense2)\n",
    "\n",
    "model = keras.Model(inputs=[input_layer], outputs=[output_layer])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1ec823-3974-468b-a579-30b3d700574b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Oddzielna klasa -- najbardziej skomplikowane przypadki. \n",
    "*Technika praktycznie identyczna do PyTorch*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09567fad-1643-41cf-a6ab-b96add2a5247",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(keras.Model):\n",
    "    def __init__(self, preprocessing_layer, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.preprocessing = preprocessing_layer\n",
    "        self.dense1 = keras.layers.Dense(300, activation=\"relu\")\n",
    "        self.dense2 = keras.layers.Dense(100, activation=\"relu\")\n",
    "        self.output_layer = keras.layers.Dense(10, activation=\"softmax\")\n",
    "\n",
    "    def call(self, x):  # Jedyna różnica względen PyTorch. Tu jest funkcja call a nie forward\n",
    "        x = self.flatten(x)\n",
    "        x = self.preprocessing(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "model = MyModel(preprocessing_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222a8eb0-b008-41ac-a812-ab4d675eb89e",
   "metadata": {},
   "source": [
    "Co do customowych metryk czy funkcji straty można to zrobić bardzo łatwo i szybko zaimplementować w postaci tego typu:\n",
    "\n",
    "```\n",
    "def huber_loss(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    \n",
    "    \n",
    "def custom_metric(y_true, y_pred):\n",
    "    squared_difference = tf.square(y_true - y_pred)\n",
    "    return tf.reduce_mean(squared_difference, axis=-1) \n",
    "```\n",
    "\n",
    "Podane wyżej funkcje mogą być bezpośrednio przekazane jako argument do model.compile(...) jako funkcja straty czy metryka. Jest to metryka typu stateless, ale ma to znaczenie głównie w implementacji własnych pętli uczących (lub mocno niestandardowych metryk, które przechowują własne wagi pomiędzy wywołaniami), przykład na końcu notebooka. Jedyna uwaga, żeby w środku takiej funkcji/metryki używać jedynie operacji matematycznych tensorflow (numpy czy sklearn nie ma opcji śledzenia gradientu co przerywa graf obliczeniowy)\n",
    "\n",
    "**Dodatkowy komentarz**, to pytanie slyszałem już od kilku osób:\n",
    "\n",
    "Co na pierwszy rzut oka może dziwić, Tensorflow nie ma implementacji metryki F1. Jest to bardzo celowe działanie, kiedyś nawet była implementacja F1, ale została specjalnie usunięta bo przynosiła więcej szkody niz pożytku. Tensorflow liczy metryki live, w trakcie uczenia, następnie je uśredniając (widać to nawet jak metryka się cały czas zmienia obok paska uczenia modelu). Metryka F1 liczona w ten sposób nie byłaby poprawna - F1 z definicji zawiera w sobie średnią, a średnia ze średnich nie jest poprawną średnią. Jeżeli chcemy znać F1 należy zrobić predykcję na całym zbiorze i następnie globalnie policzyć metrykę. W trakcie uczenia należy używać miary accuracy.\n",
    "\n",
    "Podobnie wygląda kwestia metryk precision i recall - są one definiowane jedynie dla klasyfikacji binarnej, a do klasyfikacji wieloklasowej są dostosowywane za pomocą strategii one-vs-rest, a następnie uśredniane. Z tego samego powodu (średnia ze średnich nie jest średnią) nie należy stosować precision i recall w trakcie uczenia klasyfikatora wieloklasowego. \n",
    "\n",
    "**TLDR:** Metryka F1 nigdy nie jest dobrym pomysłem. Precision i recall okej, ale tylko dla klasyfikacji binarnej"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dbd4fb-f334-457c-9f13-7d451b905ec7",
   "metadata": {},
   "source": [
    "# Kompilacja i uczenie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc0d043-f8e5-4a0b-91f9-781c7f88fbcd",
   "metadata": {},
   "source": [
    "Niesamowicie rzadko naprawdę jest potrzebna własna pętla ucząca, ponieważ jeżeli chcesz coś modyfikować w trakcie uczenia modelu do tego służą **callbacki** -- funkcje które aktywują sie w dowolnym momencie i robią zadane rzeczy. Z gotowych callbacków ciekawe są :\n",
    "* EarlyStopping -- dosć intuicyjne, mechanizm zapobiegania przeuczeniu\n",
    "* TensorBoard -- automatycznie zapisuje wszystkie metryki do wskazanego folderu\n",
    "* ModelCheckpoint -- cyklicznie zapisuje model w trakcie uczenia (przydatne gdy Collab potrafi cie randomowo wyrzucić za brak aktywności)\n",
    "* CSVLogger\n",
    "* TerminateOnNaN\n",
    "* ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba760130-5c84-41a9-819d-fe0385423bb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "callbacks = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "             keras.callbacks.TensorBoard(get_logdir()),\n",
    "             keras.callbacks.ModelCheckpoint(\"./checkpoints/model_{epoch:02d}.hdf5\", save_best_only=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e9f549-16f8-46f0-8614-bfffab587df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.Adam()\n",
    "accuracy = keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=[accuracy])\n",
    "history = model.fit(X_train, y_train, epochs=3, batch_size=64, validation_split=0.2)  # callbacks=callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59099430-57bf-4e75-abff-60e3eaeaa7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13619ee9-3aad-41f1-9ee2-417c41a4ba4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_training(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10dc4d82-814c-4d51-89ad-d9b14e2dc7d2",
   "metadata": {},
   "source": [
    "# Custom model and training process from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bd877b-3960-4a56-9241-cd258f5cb1fe",
   "metadata": {},
   "source": [
    "Klasa tf.data.Dataset pełni formę Data loadera. Zawiera wszystkie podstawowe opcje takie jak wczytywanie, batchowanie, mieszanie danych itp. Opcje jak cache, czy prefetch pozwalają przyspieszyć cały proces podawania danych do modelu przygotowując dane równolegle do uczenia (wielowątkowo) i  zachowując dane w pamięci podręcznej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f570f1d-f93a-4c35-833f-44bf83e89520",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9bd69f-2ee8-4051-a86f-ddb0bb81ab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(buffer_size=1024).batch(64).cache().prefetch(1)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test)).shuffle(buffer_size=1024).batch(64).cache().prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d860469-d4bb-4ed1-b14b-c138c87bdefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(keras.Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.dense1 = keras.layers.Dense(300, activation=\"relu\")\n",
    "        self.dense2 = keras.layers.Dense(100, activation=\"relu\")\n",
    "        self.output_layer = keras.layers.Dense(10, activation=\"softmax\")\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6fab7a-f23d-4cc5-8881-8bf3acc871d9",
   "metadata": {},
   "source": [
    "Główne elementy pętli uczącej (czyli train step i test step) mają dodany dodatkowo dektorator tf.function - dzięki temu funkcja pythone są kompilowane do statycznego grafu obliczeniowego co **znacznie** przyspiesza ich działanie (polecam usunąć dekorator i porównać). Jest to dość zaawansowana opcja i nie można każdej funkcji od tak skompilować do grafu statycznego, ta funkcja musi spełniać pewne warunki -- przede wszystkim nie można używać w środku nic co nie pochodzi z tensorflow (nie można nawet używać print, zamiast tego mamy tf.print)\n",
    "\n",
    "Opisując natomiast sam krok uczący, jest on dość prosty i analogiczny do pętli wykorzystywanej w torchu. Główną różnicą względem PyTorch jest fakt, że w TensorFlow gradienty tensorów **nie** są domyślnie śledzone. Dlatego context managerem *tf.GradientTape()* włączamy śledzenie gradientu. Moim zdaniem to jest bardziej intuicyjne... W PyTorch jest dokładnie odwrotnie: gradienty są śledzone cały czas i wyłączamy to(np. do ewaluacji) context managerem *torch.no_grad()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281dfbf5-b466-4c94-85f0-83a629ab84c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(x, y, loss_fn, metric):\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds = model(x, training=True)\n",
    "        loss_value = loss_fn(y, preds)\n",
    "\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    metric.update_state(y, preds)\n",
    "    return loss_value\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def test_step(x, y, metric):\n",
    "    val_logits = model(x, training=False)\n",
    "    metric.update_state(y, val_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2adbf3-9146-4c1c-b445-fed831cb67a3",
   "metadata": {},
   "source": [
    "Myślę, że sama funkcja fit jest dośc jasna. Jedyne ciekawostki tutaj to Progbar -- alternatywny do tqdm pasek postępu od TensorFlow (co ciekawe pozwala wypisywać metryki na samym pasku). Dodatkowo są tutaj używane metryki typu stateful. Jest to cała klasa, do której podaję tylko y_true i y_pred za pomocą metody update_state. Wszystko dzieje się w środku: liczenie, uśrednianie i zapamiętywanie całej historii metryki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8eb173-6351-4f9e-9e72-08a0850fba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_dataset, epochs, loss_fn):\n",
    "\n",
    "    train_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "    val_metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "    progress_bar = keras.utils.Progbar(epochs)\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "            train_step(x_batch_train, y_batch_train, loss_fn, train_metric)\n",
    "\n",
    "        for x_batch_val, y_batch_val in val_dataset:\n",
    "            test_step(x_batch_val, y_batch_val, val_metric)\n",
    "\n",
    "        progress_bar.add(1, values=[('accuracy', train_metric.result()), ('val_accuracy', val_metric.result())])\n",
    "        train_metric.reset_states()\n",
    "        val_metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c892c363-a5d5-4357-a7f6-f1fb2d997f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "optimizer = keras.optimizers.Adam()\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af828fb3-3f43-4cb5-a525-9f2a750a16c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fit(model, train_dataset, 5, loss_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
